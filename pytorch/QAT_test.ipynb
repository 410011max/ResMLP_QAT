{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d83ed8-43d0-458f-9a5c-d0833e60d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from run_model import evaluate_model, train_one_epoch\n",
    "from run_model import save_torchscript_model, load_torchscript_model\n",
    "from datasets import tfds_data_loader, data_loader\n",
    "import resmlp\n",
    "\n",
    "import torch.optim as optim\n",
    "from timm.models import create_model\n",
    "from timm.data import Mixup\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "from timm.utils import NativeScaler, get_state_dict, ModelEma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed33903-ca0b-46b1-a3f9-05a63e6f9c23",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385bb9a0-43c6-434f-8ce5-b97da9b1fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224\n",
    "DICT_PATH = 'E:\\ResMLP_QAT\\pytorch\\ResMLP_S24_ReLU_99dense.pth' \n",
    "\n",
    "DATA_NAME = 'imagenet2012'\n",
    "DATA_DIR = 'E:\\datasets'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LR = 1e-4\n",
    "\n",
    "WORKERS = 0 #8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6336c16-741a-417d-b9c0-40fcb9309ff3",
   "metadata": {},
   "source": [
    "## Speed Up Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea98493-73af-4a5a-9ef0-2e6cf73277f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Parallel Training (DPT) settings\n",
    "\n",
    "# device = CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# set seed\n",
    "seed = 336 # args.seed + utils.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# check for best cudnn ops before training starts.\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba8fdb-1cd7-4953-b936-34dbdb52da26",
   "metadata": {},
   "source": [
    "## Quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f5c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=False){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n"
     ]
    }
   ],
   "source": [
    "class QuantizedResMLP(nn.Module):\n",
    "    def __init__(self, model_fp32):\n",
    "        super(QuantizedResMLP, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        self.model_fp32 = model_fp32\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.model_fp32(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "# build train/val dataset\n",
    "# create sampler (if dataset from tfds, can't apply sampler) (distributed ver. to be done)\n",
    "# build up dataloader\n",
    "data_loader_train, data_loader_val, NUM_CLASSES = tfds_data_loader(\n",
    "    name=DATA_NAME,\n",
    "    root=DATA_DIR,\n",
    "    input_size=INPUT_SIZE, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=WORKERS,\n",
    ")\n",
    "\n",
    "# additional data augmentation (mixup)\n",
    "mixup_fn = Mixup(\n",
    "    mixup_alpha=0.8, cutmix_alpha=1.0, cutmix_minmax=None,\n",
    "    prob=1.0, switch_prob=0.5, mode='batch',\n",
    "    label_smoothing=0.1, num_classes=NUM_CLASSES)  \n",
    "\n",
    "# create model\n",
    "model = create_model('resmlp_24', num_classes=NUM_CLASSES).cuda()\n",
    "model.load_state_dict(torch.load(DICT_PATH), strict=False)\n",
    "\n",
    "# fuse\n",
    "fused_model = copy.deepcopy(model)\n",
    "for basic_block_name, basic_block in fused_model.blocks.named_children():\n",
    "  for sub_block_name, sub_block in basic_block.named_children():\n",
    "    if sub_block_name == \"mlp\":\n",
    "      torch.quantization.fuse_modules(\n",
    "        sub_block, [['fc1', 'act']],\n",
    "        inplace=True)\n",
    "\n",
    "# apply quant/dequant stabs\n",
    "quantized_model = QuantizedResMLP(model_fp32=fused_model)\n",
    "quantized_model.train()\n",
    "\n",
    "# quantization configurations\n",
    "quantized_model.qconfig = torch.quantization.get_default_qat_qconfig('qnnpack')\n",
    "print(quantized_model.qconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb54c48a-cc2b-4e15-b04d-f934385dc8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training QAT Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40036 [00:00<?, ?it/s]c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\ao\\quantization\\fake_quantize.py:309: UserWarning: _aminmax is deprecated as of PyTorch 1.11 and will be removed in a future release. Use aminmax instead. This warning will only appear once per process. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\ReduceAllOps.cpp:31.)\n",
      "  return torch.fused_moving_avg_obs_fake_quant(\n",
      "i: 1080 Eval Loss: 2.464:   3%|▎         | 1087/40036 [09:01<5:43:58,  1.89it/s]"
     ]
    }
   ],
   "source": [
    "# train\n",
    "print(\"Training QAT Model...\")\n",
    "quantized_model.train()\n",
    "torch.quantization.prepare_qat(quantized_model, inplace=True)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = SoftTargetCrossEntropy()\n",
    "optimizer = optim.SGD(quantized_model.parameters(),\n",
    "                        lr=LR,\n",
    "                        momentum=0.9,\n",
    "                        weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                    milestones=[100, 150],\n",
    "                                                    gamma=0.1,\n",
    "                                                    last_epoch=-1)                                                  \n",
    "                                                    \n",
    "train_one_epoch(model=quantized_model, criterion=criterion,\n",
    "                  data_loader=data_loader_train, optimizer=optimizer,\n",
    "                  device=device, epoch=1, max_norm=None,\n",
    "                  model_ema=None, mixup_fn=mixup_fn)\n",
    "#training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe59a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert weight to int8, replace model to quantized ver.\n",
    "quantized_model.cpu()\n",
    "torch.quantization.convert(quantized_model, inplace=True)\n",
    "quantized_model.eval()\n",
    "\n",
    "input_fp32 = torch.randn((1, 3, 224, 224), dtype=torch.float32, device=\"cpu\")\n",
    "quantized_model(input_fp32)\n",
    "\n",
    "SAVE_PATH = 'modeltest.pth'\n",
    "save_torchscript_model(model=quantized_model, \n",
    "                        model_dir='qat_weights', \n",
    "                        model_filename='qat_Test0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7d3bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1042/1042 [29:09<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: -1 Eval Loss: 1.842 Top1: 74.376 Top5: 90.640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "#model = create_model('resmlp_24', num_classes=NUM_CLASSES).cuda()\n",
    "quantized_model = load_torchscript_model(model_filepath='qat_weights/qat_Test0.pth', device=\"cpu\")\n",
    "\n",
    "#model.load_state_dict(torch.load(DICT_PATH), strict=False)\n",
    "# Evaluation\n",
    "quantized_model.eval()\n",
    "eval_loss, top1_acc, top5_acc = evaluate_model(model=quantized_model,\n",
    "                                                test_loader=data_loader_val,\n",
    "                                                device=\"cpu\",\n",
    "                                                criterion=criterion)\n",
    "print(\"Epoch: {:02d} Eval Loss: {:.3f} Top1: {:.3f} Top5: {:.3f}\".format(\n",
    "    -1, eval_loss, top1_acc, top5_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import run_model\n",
    "reload(run_model)\n",
    "from run_model import evaluate_model, train_one_epoch\n",
    "from run_model import save_torchscript_model, load_torchscript_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
