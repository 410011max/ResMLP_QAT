{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bit_config import *\n",
    "from utils import *\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "model = resmlp_24(pretrained=True)\n",
    "qmodel = q_resmlp24(model, full_precision_flag=True)\n",
    "\n",
    "mdict = model.state_dict()\n",
    "qmdict = qmodel.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [20, 5]\n",
    "\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "layer_name = 'layer0.gamma_2.weight'\n",
    "print(\"(min, max):  \", (qmdict[layer_name].min(), qmdict[layer_name].max()))\n",
    "print(\"(std, mean): \", torch.std_mean(qmdict[layer_name], unbiased=False))\n",
    "ax = sns.heatmap(qmdict[layer_name])\n",
    "ax.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'layer1.gamma_1.weight'\n",
    "print(\"(min, max):  \", (qmdict[layer_name].min(), qmdict[layer_name].max()))\n",
    "print(\"(std, mean): \", torch.std_mean(qmdict[layer_name], unbiased=False))\n",
    "ax = sns.heatmap(qmdict[layer_name])\n",
    "ax.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Weight Distribution of Gamma_1/Gamma_2 for Each Layer')\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for i in range(0, 24):\n",
    "  layer1_name = f'layer{i}.gamma_1.weight'\n",
    "  data1 = qmdict[layer1_name].detach().numpy().flatten()\n",
    "\n",
    "  layer2_name = f'layer{i}.gamma_2.weight'\n",
    "  data2 = qmdict[layer2_name].detach().numpy().flatten()\n",
    "\n",
    "  # data = np.concatenate([[data1], [data2]], axis=0)\n",
    "  data.append(data1)\n",
    "  data.append(data2)\n",
    "  labels.append(f'{i}g1')\n",
    "  labels.append(f'{i}g2')\n",
    "  \n",
    "# Creating plot\n",
    "bp = plt.boxplot(data, labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output[0].detach()\n",
    "    return hook\n",
    "\n",
    "getattr(qmodel, 'quant_patch').norm.register_forward_hook(get_activation('in'))\n",
    "for i in range(0, 24):\n",
    "  layer_name = f'layer{i}'\n",
    "  layer1_name = f'{i}g1'\n",
    "  layer2_name = f'{i}g2'\n",
    "  getattr(qmodel, layer_name).gamma_1.register_forward_hook(get_activation(layer1_name))\n",
    "  getattr(qmodel, layer_name).gamma_2.register_forward_hook(get_activation(layer2_name))\n",
    "\n",
    "x = torch.Tensor(np.random.rand(1, 3, 224, 224))\n",
    "output = qmodel(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Activation Distribution from Gamma_1/Gamma_2 for Each Layer')\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 5]\n",
    "# plt.rcParams[\"figure.figsize\"] = [5, 5]\n",
    "\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for name in list(activations):\n",
    "  labels.append(name)\n",
    "  # print(activations[name].shape)\n",
    "  data.append(activations[name][0].flatten())\n",
    "  \n",
    "# Creating plot\n",
    "bp = plt.boxplot(data, labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Activation Distribution from Gamma_1/Gamma_2 for Each Layer')\n",
    "# plt.rcParams[\"figure.figsize\"] = [20, 5]\n",
    "plt.rcParams[\"figure.figsize\"] = [5, 5]\n",
    "\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for name in list(activations)[2:5]:\n",
    "  labels.append(name)\n",
    "  # print(activations[name].shape)\n",
    "  data.append(activations[name][0].flatten())\n",
    "  \n",
    "# Creating plot\n",
    "bp = plt.boxplot(data, labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', Q_ResMLP24(\n",
      "  (quant_input): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (quant_patch): Q_PatchEmbed(\n",
      "    (proj): (QuantConv2d(\n",
      "      (conv): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "    ) weight_bit=4, bias_bit=32, full_precision_flag=True, quant_mode=symmetric)\n",
      "    (quant_act_int32): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (layer0): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer1): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer2): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer3): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer4): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer5): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer6): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer7): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer8): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer9): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer10): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer11): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer12): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer13): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer14): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer15): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer16): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer17): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer18): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer19): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer20): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer21): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer22): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer23): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (norm): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (head): Linear(in_features=384, out_features=1000, bias=True)\n",
      "))\n",
      "('quant_input', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('quant_patch', Q_PatchEmbed(\n",
      "  (proj): (QuantConv2d(\n",
      "    (conv): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "  ) weight_bit=4, bias_bit=32, full_precision_flag=True, quant_mode=symmetric)\n",
      "  (quant_act_int32): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm): Identity()\n",
      "))\n",
      "('quant_patch.proj', (QuantConv2d(\n",
      "  (conv): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      ") weight_bit=4, bias_bit=32, full_precision_flag=True, quant_mode=symmetric))\n",
      "('quant_patch.proj.conv', Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16)))\n",
      "('quant_patch.quant_act_int32', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('quant_patch.norm', Identity())\n",
      "('layer0', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer0.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer0.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer1.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer1.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer2.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer2.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer3.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer3.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer4.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer4.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer5.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer5.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer6.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer6.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer7.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer7.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer8.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer8.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer9.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer9.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer10.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer10.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer11.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer11.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer12.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer12.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer13.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer13.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer14.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer14.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer15.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer15.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer16.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer16.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer17.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer17.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer18.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer18.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer19.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer19.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer20.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer20.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer21.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer21.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer22.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer22.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer23.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer23.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('norm', Linear(in_features=384, out_features=384, bias=True))\n",
      "('head', Linear(in_features=384, out_features=1000, bias=True))\n"
     ]
    }
   ],
   "source": [
    "for a in qmodel.named_modules():\n",
    "  print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
