{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bit_config import *\n",
    "from utils import *\n",
    "import torch\n",
    "# from torchsummary import summary\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "model = resmlp_24(pretrained=True)\n",
    "mdict = model.state_dict()\n",
    "qmodel = q_resmlp24(model, full_precision_flag=True)\n",
    "qmdict = qmodel.state_dict()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QuantLinear' object has no attribute 'linear'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\ResMLP_QAT\\HAWQ\\model.compare.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ResMLP_QAT/HAWQ/model.compare.ipynb#ch0000008?line=4'>5</a>\u001b[0m             linear_layers\u001b[39m.\u001b[39mappend(module)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ResMLP_QAT/HAWQ/model.compare.ipynb#ch0000008?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m linear_layers\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/ResMLP_QAT/HAWQ/model.compare.ipynb#ch0000008?line=7'>8</a>\u001b[0m get_linear_layers(qmodel\u001b[39m.\u001b[39;49mlayer0)[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mlinear\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39msize()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1206\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1207\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1208\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'QuantLinear' object has no attribute 'linear'"
=======
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_layers(model):\n",
    "    conv_layers = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantLinear):\n",
    "            conv_layers.append(module)\n",
    "            # print(name)\n",
    "    return conv_layers\n",
    "  \n",
    "# get_linear_layers(qmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm1\n",
      "attn\n",
      "gamma_1\n",
      "norm2\n",
      "mlp.fc1\n",
      "mlp.fc2\n",
      "gamma_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric),\n",
       " (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric),\n",
       " (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric),\n",
       " (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric),\n",
       " (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric),\n",
       " (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric),\n",
       " (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block0 = qmodel.layer0\n",
    "get_linear_layers(block0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "quant_input\n",
      "quant_patch\n",
      "quant_patch.proj\n",
      "quant_patch.proj.conv\n",
      "quant_patch.quant_act_int32\n",
      "quant_patch.norm\n",
      "act\n",
      "layer0\n",
      "layer0.quant_act\n",
      "layer0.norm1\n",
      "layer0.quant_act1\n",
      "layer0.attn\n",
      "layer0.quant_act2\n",
      "layer0.gamma_1\n",
      "layer0.quant_act_int32_1\n",
      "layer0.norm2\n",
      "layer0.quant_act3\n",
      "layer0.mlp\n",
      "layer0.mlp.fc1\n",
      "layer0.mlp.quant_act1\n",
      "layer0.mlp.fc2\n",
      "layer0.mlp.quant_act2\n",
      "layer0.gamma_2\n",
      "layer0.quant_act_int32_2\n",
      "layer1\n",
      "layer1.quant_act\n",
      "layer1.norm1\n",
      "layer1.quant_act1\n",
      "layer1.attn\n",
      "layer1.quant_act2\n",
      "layer1.gamma_1\n",
      "layer1.quant_act_int32_1\n",
      "layer1.norm2\n",
      "layer1.quant_act3\n",
      "layer1.mlp\n",
      "layer1.mlp.fc1\n",
      "layer1.mlp.quant_act1\n",
      "layer1.mlp.fc2\n",
      "layer1.mlp.quant_act2\n",
      "layer1.gamma_2\n",
      "layer1.quant_act_int32_2\n",
      "layer2\n",
      "layer2.quant_act\n",
      "layer2.norm1\n",
      "layer2.quant_act1\n",
      "layer2.attn\n",
      "layer2.quant_act2\n",
      "layer2.gamma_1\n",
      "layer2.quant_act_int32_1\n",
      "layer2.norm2\n",
      "layer2.quant_act3\n",
      "layer2.mlp\n",
      "layer2.mlp.fc1\n",
      "layer2.mlp.quant_act1\n",
      "layer2.mlp.fc2\n",
      "layer2.mlp.quant_act2\n",
      "layer2.gamma_2\n",
      "layer2.quant_act_int32_2\n",
      "layer3\n",
      "layer3.quant_act\n",
      "layer3.norm1\n",
      "layer3.quant_act1\n",
      "layer3.attn\n",
      "layer3.quant_act2\n",
      "layer3.gamma_1\n",
      "layer3.quant_act_int32_1\n",
      "layer3.norm2\n",
      "layer3.quant_act3\n",
      "layer3.mlp\n",
      "layer3.mlp.fc1\n",
      "layer3.mlp.quant_act1\n",
      "layer3.mlp.fc2\n",
      "layer3.mlp.quant_act2\n",
      "layer3.gamma_2\n",
      "layer3.quant_act_int32_2\n",
      "layer4\n",
      "layer4.quant_act\n",
      "layer4.norm1\n",
      "layer4.quant_act1\n",
      "layer4.attn\n",
      "layer4.quant_act2\n",
      "layer4.gamma_1\n",
      "layer4.quant_act_int32_1\n",
      "layer4.norm2\n",
      "layer4.quant_act3\n",
      "layer4.mlp\n",
      "layer4.mlp.fc1\n",
      "layer4.mlp.quant_act1\n",
      "layer4.mlp.fc2\n",
      "layer4.mlp.quant_act2\n",
      "layer4.gamma_2\n",
      "layer4.quant_act_int32_2\n",
      "layer5\n",
      "layer5.quant_act\n",
      "layer5.norm1\n",
      "layer5.quant_act1\n",
      "layer5.attn\n",
      "layer5.quant_act2\n",
      "layer5.gamma_1\n",
      "layer5.quant_act_int32_1\n",
      "layer5.norm2\n",
      "layer5.quant_act3\n",
      "layer5.mlp\n",
      "layer5.mlp.fc1\n",
      "layer5.mlp.quant_act1\n",
      "layer5.mlp.fc2\n",
      "layer5.mlp.quant_act2\n",
      "layer5.gamma_2\n",
      "layer5.quant_act_int32_2\n",
      "layer6\n",
      "layer6.quant_act\n",
      "layer6.norm1\n",
      "layer6.quant_act1\n",
      "layer6.attn\n",
      "layer6.quant_act2\n",
      "layer6.gamma_1\n",
      "layer6.quant_act_int32_1\n",
      "layer6.norm2\n",
      "layer6.quant_act3\n",
      "layer6.mlp\n",
      "layer6.mlp.fc1\n",
      "layer6.mlp.quant_act1\n",
      "layer6.mlp.fc2\n",
      "layer6.mlp.quant_act2\n",
      "layer6.gamma_2\n",
      "layer6.quant_act_int32_2\n",
      "layer7\n",
      "layer7.quant_act\n",
      "layer7.norm1\n",
      "layer7.quant_act1\n",
      "layer7.attn\n",
      "layer7.quant_act2\n",
      "layer7.gamma_1\n",
      "layer7.quant_act_int32_1\n",
      "layer7.norm2\n",
      "layer7.quant_act3\n",
      "layer7.mlp\n",
      "layer7.mlp.fc1\n",
      "layer7.mlp.quant_act1\n",
      "layer7.mlp.fc2\n",
      "layer7.mlp.quant_act2\n",
      "layer7.gamma_2\n",
      "layer7.quant_act_int32_2\n",
      "layer8\n",
      "layer8.quant_act\n",
      "layer8.norm1\n",
      "layer8.quant_act1\n",
      "layer8.attn\n",
      "layer8.quant_act2\n",
      "layer8.gamma_1\n",
      "layer8.quant_act_int32_1\n",
      "layer8.norm2\n",
      "layer8.quant_act3\n",
      "layer8.mlp\n",
      "layer8.mlp.fc1\n",
      "layer8.mlp.quant_act1\n",
      "layer8.mlp.fc2\n",
      "layer8.mlp.quant_act2\n",
      "layer8.gamma_2\n",
      "layer8.quant_act_int32_2\n",
      "layer9\n",
      "layer9.quant_act\n",
      "layer9.norm1\n",
      "layer9.quant_act1\n",
      "layer9.attn\n",
      "layer9.quant_act2\n",
      "layer9.gamma_1\n",
      "layer9.quant_act_int32_1\n",
      "layer9.norm2\n",
      "layer9.quant_act3\n",
      "layer9.mlp\n",
      "layer9.mlp.fc1\n",
      "layer9.mlp.quant_act1\n",
      "layer9.mlp.fc2\n",
      "layer9.mlp.quant_act2\n",
      "layer9.gamma_2\n",
      "layer9.quant_act_int32_2\n",
      "layer10\n",
      "layer10.quant_act\n",
      "layer10.norm1\n",
      "layer10.quant_act1\n",
      "layer10.attn\n",
      "layer10.quant_act2\n",
      "layer10.gamma_1\n",
      "layer10.quant_act_int32_1\n",
      "layer10.norm2\n",
      "layer10.quant_act3\n",
      "layer10.mlp\n",
      "layer10.mlp.fc1\n",
      "layer10.mlp.quant_act1\n",
      "layer10.mlp.fc2\n",
      "layer10.mlp.quant_act2\n",
      "layer10.gamma_2\n",
      "layer10.quant_act_int32_2\n",
      "layer11\n",
      "layer11.quant_act\n",
      "layer11.norm1\n",
      "layer11.quant_act1\n",
      "layer11.attn\n",
      "layer11.quant_act2\n",
      "layer11.gamma_1\n",
      "layer11.quant_act_int32_1\n",
      "layer11.norm2\n",
      "layer11.quant_act3\n",
      "layer11.mlp\n",
      "layer11.mlp.fc1\n",
      "layer11.mlp.quant_act1\n",
      "layer11.mlp.fc2\n",
      "layer11.mlp.quant_act2\n",
      "layer11.gamma_2\n",
      "layer11.quant_act_int32_2\n",
      "layer12\n",
      "layer12.quant_act\n",
      "layer12.norm1\n",
      "layer12.quant_act1\n",
      "layer12.attn\n",
      "layer12.quant_act2\n",
      "layer12.gamma_1\n",
      "layer12.quant_act_int32_1\n",
      "layer12.norm2\n",
      "layer12.quant_act3\n",
      "layer12.mlp\n",
      "layer12.mlp.fc1\n",
      "layer12.mlp.quant_act1\n",
      "layer12.mlp.fc2\n",
      "layer12.mlp.quant_act2\n",
      "layer12.gamma_2\n",
      "layer12.quant_act_int32_2\n",
      "layer13\n",
      "layer13.quant_act\n",
      "layer13.norm1\n",
      "layer13.quant_act1\n",
      "layer13.attn\n",
      "layer13.quant_act2\n",
      "layer13.gamma_1\n",
      "layer13.quant_act_int32_1\n",
      "layer13.norm2\n",
      "layer13.quant_act3\n",
      "layer13.mlp\n",
      "layer13.mlp.fc1\n",
      "layer13.mlp.quant_act1\n",
      "layer13.mlp.fc2\n",
      "layer13.mlp.quant_act2\n",
      "layer13.gamma_2\n",
      "layer13.quant_act_int32_2\n",
      "layer14\n",
      "layer14.quant_act\n",
      "layer14.norm1\n",
      "layer14.quant_act1\n",
      "layer14.attn\n",
      "layer14.quant_act2\n",
      "layer14.gamma_1\n",
      "layer14.quant_act_int32_1\n",
      "layer14.norm2\n",
      "layer14.quant_act3\n",
      "layer14.mlp\n",
      "layer14.mlp.fc1\n",
      "layer14.mlp.quant_act1\n",
      "layer14.mlp.fc2\n",
      "layer14.mlp.quant_act2\n",
      "layer14.gamma_2\n",
      "layer14.quant_act_int32_2\n",
      "layer15\n",
      "layer15.quant_act\n",
      "layer15.norm1\n",
      "layer15.quant_act1\n",
      "layer15.attn\n",
      "layer15.quant_act2\n",
      "layer15.gamma_1\n",
      "layer15.quant_act_int32_1\n",
      "layer15.norm2\n",
      "layer15.quant_act3\n",
      "layer15.mlp\n",
      "layer15.mlp.fc1\n",
      "layer15.mlp.quant_act1\n",
      "layer15.mlp.fc2\n",
      "layer15.mlp.quant_act2\n",
      "layer15.gamma_2\n",
      "layer15.quant_act_int32_2\n",
      "layer16\n",
      "layer16.quant_act\n",
      "layer16.norm1\n",
      "layer16.quant_act1\n",
      "layer16.attn\n",
      "layer16.quant_act2\n",
      "layer16.gamma_1\n",
      "layer16.quant_act_int32_1\n",
      "layer16.norm2\n",
      "layer16.quant_act3\n",
      "layer16.mlp\n",
      "layer16.mlp.fc1\n",
      "layer16.mlp.quant_act1\n",
      "layer16.mlp.fc2\n",
      "layer16.mlp.quant_act2\n",
      "layer16.gamma_2\n",
      "layer16.quant_act_int32_2\n",
      "layer17\n",
      "layer17.quant_act\n",
      "layer17.norm1\n",
      "layer17.quant_act1\n",
      "layer17.attn\n",
      "layer17.quant_act2\n",
      "layer17.gamma_1\n",
      "layer17.quant_act_int32_1\n",
      "layer17.norm2\n",
      "layer17.quant_act3\n",
      "layer17.mlp\n",
      "layer17.mlp.fc1\n",
      "layer17.mlp.quant_act1\n",
      "layer17.mlp.fc2\n",
      "layer17.mlp.quant_act2\n",
      "layer17.gamma_2\n",
      "layer17.quant_act_int32_2\n",
      "layer18\n",
      "layer18.quant_act\n",
      "layer18.norm1\n",
      "layer18.quant_act1\n",
      "layer18.attn\n",
      "layer18.quant_act2\n",
      "layer18.gamma_1\n",
      "layer18.quant_act_int32_1\n",
      "layer18.norm2\n",
      "layer18.quant_act3\n",
      "layer18.mlp\n",
      "layer18.mlp.fc1\n",
      "layer18.mlp.quant_act1\n",
      "layer18.mlp.fc2\n",
      "layer18.mlp.quant_act2\n",
      "layer18.gamma_2\n",
      "layer18.quant_act_int32_2\n",
      "layer19\n",
      "layer19.quant_act\n",
      "layer19.norm1\n",
      "layer19.quant_act1\n",
      "layer19.attn\n",
      "layer19.quant_act2\n",
      "layer19.gamma_1\n",
      "layer19.quant_act_int32_1\n",
      "layer19.norm2\n",
      "layer19.quant_act3\n",
      "layer19.mlp\n",
      "layer19.mlp.fc1\n",
      "layer19.mlp.quant_act1\n",
      "layer19.mlp.fc2\n",
      "layer19.mlp.quant_act2\n",
      "layer19.gamma_2\n",
      "layer19.quant_act_int32_2\n",
      "layer20\n",
      "layer20.quant_act\n",
      "layer20.norm1\n",
      "layer20.quant_act1\n",
      "layer20.attn\n",
      "layer20.quant_act2\n",
      "layer20.gamma_1\n",
      "layer20.quant_act_int32_1\n",
      "layer20.norm2\n",
      "layer20.quant_act3\n",
      "layer20.mlp\n",
      "layer20.mlp.fc1\n",
      "layer20.mlp.quant_act1\n",
      "layer20.mlp.fc2\n",
      "layer20.mlp.quant_act2\n",
      "layer20.gamma_2\n",
      "layer20.quant_act_int32_2\n",
      "layer21\n",
      "layer21.quant_act\n",
      "layer21.norm1\n",
      "layer21.quant_act1\n",
      "layer21.attn\n",
      "layer21.quant_act2\n",
      "layer21.gamma_1\n",
      "layer21.quant_act_int32_1\n",
      "layer21.norm2\n",
      "layer21.quant_act3\n",
      "layer21.mlp\n",
      "layer21.mlp.fc1\n",
      "layer21.mlp.quant_act1\n",
      "layer21.mlp.fc2\n",
      "layer21.mlp.quant_act2\n",
      "layer21.gamma_2\n",
      "layer21.quant_act_int32_2\n",
      "layer22\n",
      "layer22.quant_act\n",
      "layer22.norm1\n",
      "layer22.quant_act1\n",
      "layer22.attn\n",
      "layer22.quant_act2\n",
      "layer22.gamma_1\n",
      "layer22.quant_act_int32_1\n",
      "layer22.norm2\n",
      "layer22.quant_act3\n",
      "layer22.mlp\n",
      "layer22.mlp.fc1\n",
      "layer22.mlp.quant_act1\n",
      "layer22.mlp.fc2\n",
      "layer22.mlp.quant_act2\n",
      "layer22.gamma_2\n",
      "layer22.quant_act_int32_2\n",
      "layer23\n",
      "layer23.quant_act\n",
      "layer23.norm1\n",
      "layer23.quant_act1\n",
      "layer23.attn\n",
      "layer23.quant_act2\n",
      "layer23.gamma_1\n",
      "layer23.quant_act_int32_1\n",
      "layer23.norm2\n",
      "layer23.quant_act3\n",
      "layer23.mlp\n",
      "layer23.mlp.fc1\n",
      "layer23.mlp.quant_act1\n",
      "layer23.mlp.fc2\n",
      "layer23.mlp.quant_act2\n",
      "layer23.gamma_2\n",
      "layer23.quant_act_int32_2\n",
      "norm\n",
      "head\n"
>>>>>>> c7a301129cab30520354007cb77f85dcec41a643
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "def get_linear_layers(model):\n",
    "    linear_layers = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantLinear):\n",
    "            linear_layers.append(module)\n",
    "    return linear_layers\n",
    "\n",
    "get_linear_layers(qmodel.layer0)[0].linear.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_layer_equalization(model):\n",
    "    conv_layers = get_linear_layers(model)\n",
    "    '''\n",
    "    Perform Cross Layer Scaling :\n",
    "    Iterate modules until scale value is converged up to 1e-8 magnitude\n",
    "    '''\n",
    "    S_history = dict()\n",
    "    eps = 1e-8\n",
    "    converged = [False] * (len(conv_layers)-1)\n",
    "    with torch.no_grad(): \n",
    "        while not np.all(converged):\n",
    "            for idx in range(1, len(conv_layers)):\n",
    "\n",
    "                prev, curr = conv_layers[idx-1].linear, conv_layers[idx].linear\n",
    "                out_channel_prev, in_channel_curr = prev.weight.size()[0], curr.weight.size()[1]\n",
    "\n",
    "                '''\n",
    "                prev : [Out_channel, In_channel, H, W]\n",
    "                curr : [Out_channel, In_channel, H, W]\n",
    "                For prev layer, we need to obtain a range of 'output channel'\n",
    "                For curr layer, we need to obtain a range of 'input channel'\n",
    "                '''\n",
    "                range_1 = 2.*torch.abs(prev.weight).max(axis = 1)[0].max(axis = 1)[0].max(axis = 1)[0]\n",
    "                range_2 = 2.*torch.abs(curr.weight).max(axis = 0)[0].max(axis = -1)[0].max(axis = -1)[0]\n",
    "\n",
    "                S = torch.sqrt(range_1 * range_2) / range_2\n",
    "\n",
    "                if idx in S_history:\n",
    "                    prev_s = S_history[idx]\n",
    "                    if np.all(np.isclose(S.cpu().numpy(), prev_s.cpu().numpy(), atol = eps)):\n",
    "                        converged[idx-1] = True\n",
    "                        continue\n",
    "                    else:\n",
    "                        converged[idx-1] = False\n",
    "                s_dim = S.size()[0]\n",
    "                prev.weight.data.div_(S.view(s_dim, 1, 1, 1))\n",
    "                prev.bias.data.div_(S)\n",
    "                prev.gamma.data.div_(S)\n",
    "                prev.beta.data.div_(S)\n",
    "                # Generic Conv layer\n",
    "                if in_channel_curr == out_channel_prev: \n",
    "                    curr.weight.data.mul_( S.view(1, s_dim, 1, 1) )\n",
    "                else:\n",
    "                    # Depthwise Convolution\n",
    "                    curr.weight.data.mul_( S.view(s_dim, 1, 1, 1) )\n",
    "                S_history[idx] = S\n",
    "    return conv_layers"
=======
    "for n, m in qmodel.named_modules():\n",
    "  if \"layer0\" in n: \n",
    "    print(n, m)"
>>>>>>> c7a301129cab30520354007cb77f85dcec41a643
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [20, 5]\n",
    "\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "layer_name = 'layer0.gamma_2.weight'\n",
    "print(\"(min, max):  \", (qmdict[layer_name].min(), qmdict[layer_name].max()))\n",
    "print(\"(std, mean): \", torch.std_mean(qmdict[layer_name], unbiased=False))\n",
    "ax = sns.heatmap(qmdict[layer_name])\n",
    "ax.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'layer1.gamma_1.weight'\n",
    "print(\"(min, max):  \", (qmdict[layer_name].min(), qmdict[layer_name].max()))\n",
    "print(\"(std, mean): \", torch.std_mean(qmdict[layer_name], unbiased=False))\n",
    "ax = sns.heatmap(qmdict[layer_name])\n",
    "ax.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Weight Distribution of Gamma_1/Gamma_2 for Each Layer')\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for i in range(0, 24):\n",
    "  layer1_name = f'layer{i}.gamma_1.weight'\n",
    "  data1 = qmdict[layer1_name].detach().numpy().flatten()\n",
    "\n",
    "  layer2_name = f'layer{i}.gamma_2.weight'\n",
    "  data2 = qmdict[layer2_name].detach().numpy().flatten()\n",
    "\n",
    "  # data = np.concatenate([[data1], [data2]], axis=0)\n",
    "  data.append(data1)\n",
    "  data.append(data2)\n",
    "  labels.append(f'{i}g1')\n",
    "  labels.append(f'{i}g2')\n",
    "  \n",
    "# Creating plot\n",
    "bp = plt.boxplot(data, labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Weight Distribution of Gamma_1/Gamma_2 for Each Layer')\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for i in range(0, 24):\n",
    "  layer1_name = f'layer{i}.gamma_1.weight'\n",
    "  data1 = qmdict[layer1_name].detach().numpy().flatten()\n",
    "\n",
    "  layer2_name = f'layer{i}.gamma_2.weight'\n",
    "  data2 = qmdict[layer2_name].detach().numpy().flatten()\n",
    "\n",
    "  # data = np.concatenate([[data1], [data2]], axis=0)\n",
    "  data.append(data1)\n",
    "  data.append(data2)\n",
    "  labels.append(f'{i}g1')\n",
    "  labels.append(f'{i}g2')\n",
    "  \n",
    "# Creating plot\n",
    "bp = plt.boxplot(data, labels=labels)\n",
    "plt.savefig('w2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "train_resolution = 224  \n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomResizedCrop(train_resolution),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "# simulate input\n",
    "x = np.array(np.rint(np.random.rand(500, 375, 3) * 255), dtype=np.uint8)\n",
    "x = transform(x).unsqueeze(0)\n",
    "# cuda0 = torch.device('cuda:0')\n",
    "# x = x.to(cuda0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output[0].detach()\n",
    "    return hook\n",
    "\n",
    "getattr(qmodel, 'quant_patch').norm.register_forward_hook(get_activation('in'))\n",
    "for i in range(0, 24):\n",
    "  layer_name = f'layer{i}'\n",
    "  layer1_name = f'{i}g1'\n",
    "  layer2_name = f'{i}g2'\n",
    "  getattr(qmodel, layer_name).gamma_1.register_forward_hook(get_activation(layer1_name))\n",
    "  getattr(qmodel, layer_name).gamma_2.register_forward_hook(get_activation(layer2_name))\n",
    "\n",
    "output = qmodel(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Activation Distribution from Gamma_1/Gamma_2 for Each Layer')\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 5]\n",
    "# plt.rcParams[\"figure.figsize\"] = [5, 5]\n",
    "\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "from_layers=0\n",
    "to_layers=20\n",
    "for name in list(activations)[from_layers*2 : to_layers*2+1]:\n",
    "  labels.append(name)\n",
    "  # print(activations[name].shape)\n",
    "  data.append(activations[name][0].flatten())\n",
    "  \n",
    "# Creating plot\n",
    "bp = plt.boxplot(data, labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', Q_ResMLP24(\n",
      "  (quant_input): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (quant_patch): Q_PatchEmbed(\n",
      "    (proj): (QuantConv2d(\n",
      "      (conv): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "    ) weight_bit=4, bias_bit=32, full_precision_flag=True, quant_mode=symmetric)\n",
      "    (quant_act_int32): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (layer0): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer1): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer2): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer3): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer4): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer5): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer6): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer7): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer8): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer9): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer10): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer11): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer12): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer13): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer14): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer15): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer16): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer17): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer18): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer19): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer20): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer21): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer22): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer23): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (norm): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (head): Linear(in_features=384, out_features=1000, bias=True)\n",
      "))\n",
      "('quant_input', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('quant_patch', Q_PatchEmbed(\n",
      "  (proj): (QuantConv2d(\n",
      "    (conv): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "  ) weight_bit=4, bias_bit=32, full_precision_flag=True, quant_mode=symmetric)\n",
      "  (quant_act_int32): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm): Identity()\n",
      "))\n",
      "('quant_patch.proj', (QuantConv2d(\n",
      "  (conv): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      ") weight_bit=4, bias_bit=32, full_precision_flag=True, quant_mode=symmetric))\n",
      "('quant_patch.proj.conv', Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16)))\n",
      "('quant_patch.quant_act_int32', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('quant_patch.norm', Identity())\n",
      "('layer0', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer0.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer0.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer1.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer1.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer2.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer2.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer3.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer3.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer4.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer4.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer5.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer5.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer6.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer6.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer7.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer7.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer8.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer8.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer9.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer9.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer10.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer10.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer11.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer11.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer12.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer12.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer13.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer13.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer14.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer14.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer15.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer15.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer16.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer16.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer17.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer17.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer18.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer18.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer19.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer19.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer20.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer20.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer21.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer21.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer22.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer22.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer23.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer23.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('norm', Linear(in_features=384, out_features=384, bias=True))\n",
      "('head', Linear(in_features=384, out_features=1000, bias=True))\n"
     ]
    }
   ],
   "source": [
    "for a in qmodel.named_modules():\n",
    "  print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
