{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bit_config import *\n",
    "from utils import *\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "model = resmlp_24(pretrained=True)\n",
    "qmodel = q_resmlp24(model, full_precision_flag=True)\n",
    "\n",
    "mdict = model.state_dict()\n",
    "qmdict = qmodel.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QuantLinear' object has no attribute 'linear'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\ResMLP_QAT\\HAWQ\\model.compare.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ResMLP_QAT/HAWQ/model.compare.ipynb#ch0000008?line=4'>5</a>\u001b[0m             linear_layers\u001b[39m.\u001b[39mappend(module)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ResMLP_QAT/HAWQ/model.compare.ipynb#ch0000008?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m linear_layers\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/ResMLP_QAT/HAWQ/model.compare.ipynb#ch0000008?line=7'>8</a>\u001b[0m get_linear_layers(qmodel\u001b[39m.\u001b[39;49mlayer0)[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mlinear\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39msize()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1206\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1207\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1208\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'QuantLinear' object has no attribute 'linear'"
     ]
    }
   ],
   "source": [
    "def get_linear_layers(model):\n",
    "    linear_layers = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantLinear):\n",
    "            linear_layers.append(module)\n",
    "    return linear_layers\n",
    "\n",
    "get_linear_layers(qmodel.layer0)[0].linear.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_layer_equalization(model):\n",
    "    conv_layers = get_linear_layers(model)\n",
    "    '''\n",
    "    Perform Cross Layer Scaling :\n",
    "    Iterate modules until scale value is converged up to 1e-8 magnitude\n",
    "    '''\n",
    "    S_history = dict()\n",
    "    eps = 1e-8\n",
    "    converged = [False] * (len(conv_layers)-1)\n",
    "    with torch.no_grad(): \n",
    "        while not np.all(converged):\n",
    "            for idx in range(1, len(conv_layers)):\n",
    "\n",
    "                prev, curr = conv_layers[idx-1].linear, conv_layers[idx].linear\n",
    "                out_channel_prev, in_channel_curr = prev.weight.size()[0], curr.weight.size()[1]\n",
    "\n",
    "                '''\n",
    "                prev : [Out_channel, In_channel, H, W]\n",
    "                curr : [Out_channel, In_channel, H, W]\n",
    "                For prev layer, we need to obtain a range of 'output channel'\n",
    "                For curr layer, we need to obtain a range of 'input channel'\n",
    "                '''\n",
    "                range_1 = 2.*torch.abs(prev.weight).max(axis = 1)[0].max(axis = 1)[0].max(axis = 1)[0]\n",
    "                range_2 = 2.*torch.abs(curr.weight).max(axis = 0)[0].max(axis = -1)[0].max(axis = -1)[0]\n",
    "\n",
    "                S = torch.sqrt(range_1 * range_2) / range_2\n",
    "\n",
    "                if idx in S_history:\n",
    "                    prev_s = S_history[idx]\n",
    "                    if np.all(np.isclose(S.cpu().numpy(), prev_s.cpu().numpy(), atol = eps)):\n",
    "                        converged[idx-1] = True\n",
    "                        continue\n",
    "                    else:\n",
    "                        converged[idx-1] = False\n",
    "                s_dim = S.size()[0]\n",
    "                prev.weight.data.div_(S.view(s_dim, 1, 1, 1))\n",
    "                prev.bias.data.div_(S)\n",
    "                prev.gamma.data.div_(S)\n",
    "                prev.beta.data.div_(S)\n",
    "                # Generic Conv layer\n",
    "                if in_channel_curr == out_channel_prev: \n",
    "                    curr.weight.data.mul_( S.view(1, s_dim, 1, 1) )\n",
    "                else:\n",
    "                    # Depthwise Convolution\n",
    "                    curr.weight.data.mul_( S.view(s_dim, 1, 1, 1) )\n",
    "                S_history[idx] = S\n",
    "    return conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [20, 5]\n",
    "\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "layer_name = 'layer0.gamma_2.weight'\n",
    "print(\"(min, max):  \", (qmdict[layer_name].min(), qmdict[layer_name].max()))\n",
    "print(\"(std, mean): \", torch.std_mean(qmdict[layer_name], unbiased=False))\n",
    "ax = sns.heatmap(qmdict[layer_name])\n",
    "ax.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'layer1.gamma_1.weight'\n",
    "print(\"(min, max):  \", (qmdict[layer_name].min(), qmdict[layer_name].max()))\n",
    "print(\"(std, mean): \", torch.std_mean(qmdict[layer_name], unbiased=False))\n",
    "ax = sns.heatmap(qmdict[layer_name])\n",
    "ax.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Weight Distribution of Gamma_1/Gamma_2 for Each Layer')\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for i in range(0, 24):\n",
    "  layer1_name = f'layer{i}.gamma_1.weight'\n",
    "  data1 = qmdict[layer1_name].detach().numpy().flatten()\n",
    "\n",
    "  layer2_name = f'layer{i}.gamma_2.weight'\n",
    "  data2 = qmdict[layer2_name].detach().numpy().flatten()\n",
    "\n",
    "  # data = np.concatenate([[data1], [data2]], axis=0)\n",
    "  data.append(data1)\n",
    "  data.append(data2)\n",
    "  labels.append(f'{i}g1')\n",
    "  labels.append(f'{i}g2')\n",
    "  \n",
    "# Creating plot\n",
    "bp = plt.boxplot(data, labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "train_resolution = 224  \n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomResizedCrop(train_resolution),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "# simulate input\n",
    "x = np.array(np.rint(np.random.rand(500, 375, 3) * 255), dtype=np.uint8)\n",
    "x = transform(x).unsqueeze(0)\n",
    "# cuda0 = torch.device('cuda:0')\n",
    "# x = x.to(cuda0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output[0].detach()\n",
    "    return hook\n",
    "\n",
    "getattr(qmodel, 'quant_patch').norm.register_forward_hook(get_activation('in'))\n",
    "for i in range(0, 24):\n",
    "  layer_name = f'layer{i}'\n",
    "  layer1_name = f'{i}g1'\n",
    "  layer2_name = f'{i}g2'\n",
    "  getattr(qmodel, layer_name).gamma_1.register_forward_hook(get_activation(layer1_name))\n",
    "  getattr(qmodel, layer_name).gamma_2.register_forward_hook(get_activation(layer2_name))\n",
    "\n",
    "output = qmodel(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Activation Distribution from Gamma_1/Gamma_2 for Each Layer')\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 5]\n",
    "# plt.rcParams[\"figure.figsize\"] = [5, 5]\n",
    "\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "from_layers=0\n",
    "to_layers=20\n",
    "for name in list(activations)[from_layers*2 : to_layers*2+1]:\n",
    "  labels.append(name)\n",
    "  # print(activations[name].shape)\n",
    "  data.append(activations[name][0].flatten())\n",
    "  \n",
    "# Creating plot\n",
    "bp = plt.boxplot(data, labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', Q_ResMLP24(\n",
      "  (quant_input): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (quant_patch): Q_PatchEmbed(\n",
      "    (proj): (QuantConv2d(\n",
      "      (conv): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "    ) weight_bit=4, bias_bit=32, full_precision_flag=True, quant_mode=symmetric)\n",
      "    (quant_act_int32): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (layer0): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer1): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer2): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer3): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer4): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer5): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer6): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer7): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer8): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer9): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer10): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer11): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer12): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer13): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer14): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer15): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer16): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer17): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer18): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer19): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer20): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer21): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer22): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (layer23): Q_Layer(\n",
      "    (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (mlp): Q_Mlp(\n",
      "      (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "      (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "      (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    )\n",
      "    (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (norm): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (head): Linear(in_features=384, out_features=1000, bias=True)\n",
      "))\n",
      "('quant_input', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('quant_patch', Q_PatchEmbed(\n",
      "  (proj): (QuantConv2d(\n",
      "    (conv): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "  ) weight_bit=4, bias_bit=32, full_precision_flag=True, quant_mode=symmetric)\n",
      "  (quant_act_int32): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm): Identity()\n",
      "))\n",
      "('quant_patch.proj', (QuantConv2d(\n",
      "  (conv): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      ") weight_bit=4, bias_bit=32, full_precision_flag=True, quant_mode=symmetric))\n",
      "('quant_patch.proj.conv', Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16)))\n",
      "('quant_patch.quant_act_int32', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('quant_patch.norm', Identity())\n",
      "('layer0', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer0.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer0.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer0.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer0.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer1.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer1.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer1.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer1.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer2.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer2.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer2.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer2.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer3.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer3.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer3.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer3.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer4.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer4.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer4.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer4.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer5.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer5.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer5.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer5.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer6.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer6.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer6.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer6.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer7.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer7.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer7.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer7.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer8.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer8.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer8.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer8.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer9.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer9.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer9.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer9.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer10.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer10.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer10.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer10.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer11.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer11.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer11.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer11.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer12.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer12.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer12.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer12.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer13.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer13.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer13.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer13.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer14.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer14.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer14.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer14.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer15.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer15.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer15.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer15.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer16.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer16.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer16.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer16.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer17.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer17.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer17.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer17.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer18.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer18.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer18.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer18.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer19.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer19.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer19.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer19.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer20.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer20.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer20.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer20.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer21.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer21.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer21.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer21.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer22.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer22.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer22.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer22.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23', Q_Layer(\n",
      "  (quant_act): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (attn): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (gamma_1): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (norm2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act3): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (mlp): Q_Mlp(\n",
      "    (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "    (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (gamma_2): (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act_int32_2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer23.quant_act', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.norm1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.attn', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.gamma_1', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act_int32_1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.norm2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act3', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.mlp', Q_Mlp(\n",
      "  (fc1): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act1): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (fc2): (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric)\n",
      "  (quant_act2): QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "))\n",
      "('layer23.mlp.fc1', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.mlp.quant_act1', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.mlp.fc2', (QuantLinear() weight_bit=4, bias_bit=32, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.mlp.quant_act2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('layer23.gamma_2', (QuantLinear() weight_bit=4, bias_bit=None, full_precision_flag=True, quantize_fn=symmetric))\n",
      "('layer23.quant_act_int32_2', QuantAct(activation_bit=4, full_precision_flag=True, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00))\n",
      "('norm', Linear(in_features=384, out_features=384, bias=True))\n",
      "('head', Linear(in_features=384, out_features=1000, bias=True))\n"
     ]
    }
   ],
   "source": [
    "for a in qmodel.named_modules():\n",
    "  print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
